# ğŸ§  AI Model Router

A smart, lightweight AI orchestration system that intelligently routes user queries to the most suitable AI model based on intent. Built with **FastAPI**, **Streamlit**, and **Machine Learning**.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.95%2B-009688)
![Streamlit](https://img.shields.io/badge/Streamlit-1.22%2B-FF4B4B)
![Ollama](https://img.shields.io/badge/Ollama-Llama3.2-black)

## ğŸ“– Overview

**AI Model Router** solves the "one model fits all" inefficiency. Instead of sending every query to a massive, expensive model, this system analyzes the user's intent (e.g., Creative, Factual, Simple Greeting) and routes it to a specialized model optimized for that task.

### How It Works
1. **User asks a question** via the Streamlit UI.
2. **Intent Classifier** (Logistic Regression + Sentence Transformers) predicts the category:
   - `Creative` / `Factual` / `General` â†’ **Llama 3.2** (via Ollama)
   - `Simple` / `Greeting` â†’ **Flan-T5 Large** (Hugging Face)
3. **The selected model generates a response.**
4. **The result is displayed** in the modern, dark-themed UI.

---

## âœ¨ Features

- **ğŸš€ Intelligent Routing:** Uses ML-based embedding classification (not just keywords) to determine user intent.
- **ğŸ¨ Modern UI:** A beautiful, dark-themed interface built with Streamlit.
- **âš¡ Hybrid AI Architecture:**
  - **Local LLM:** Integrates with **Ollama (Llama 3.2)** for complex tasks.
  - **Hugging Face:** Uses **Google Flan-T5** for quick, creative, or simple conversational tasks.
- **ğŸ”Œ API-First Design:** Backend is decoupled using FastAPI, allowing for easy expansion.

---

## ğŸ› ï¸ Tech Stack

- **Frontend:** Streamlit
- **Backend:** FastAPI, Uvicorn
- **ML & NLP:** Sentence-Transformers, Scikit-learn, PyTorch, Hugging Face Transformers
- **LLM Serving:** Ollama (Local Llama 3.2)

---

## ğŸ“‚ Project Structure

```bash
AI-Model-Router/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ gpt_model.py       # Handles Google Flan-T5 logic
â”‚   â”‚   â”œâ”€â”€ local_model.py     # Handles Ollama (Llama 3.2) logic
â”‚   â”‚   â””â”€â”€ simple_model.py    # Fallback/Test model
â”‚   â”œâ”€â”€ classifier.py          # (Deprecated) Keyword classifier
â”‚   â”œâ”€â”€ intent_classifier.py   # ML-based Intent Classifier (Logistic Regression)
â”‚   â”œâ”€â”€ main.py                # FastAPI entry point
â”‚   â”œâ”€â”€ requirements.txt       # Backend dependencies
â”‚   â””â”€â”€ router.py              # Main routing logic
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
